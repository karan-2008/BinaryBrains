"""
AI Insight Engine — Phase 3/4.

Generates natural-language advisory insights by calling a local Ollama instance.
This module is the ONLY place where LLM calls are made.

STRICT RULES:
- The AI does NOT perform calculations.
- The AI only explains pre-computed data.
- All numeric values are injected into the prompt, never generated by the model.
"""

import os
import requests
from app.utils.text_parser import sanitize_ai_response
from app.utils.logger import get_logger

logger = get_logger(__name__)

# ---------------------------------------------------------------------------
# Ollama Configuration
# ---------------------------------------------------------------------------
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
OLLAMA_API_KEY = os.getenv("OLLAMA_API_KEY", "")
MODEL_NAME = os.getenv("OLLAMA_MODEL", "deepseek-v3.1671b-cloud")


def generate_drought_insight(
    village_name: str,
    population: int,
    wsi: float,
    status: str,
    r_dev: float,
    g_drop: float,
    tankers: int,
    target_language: str = "English",
) -> str:
    """
    Injects deterministic math results into a strict prompt and calls local Ollama.

    Args:
        village_name: Name of the village.
        population: Village population.
        wsi: Pre-computed Water Stress Index (0–100).
        status: Human-readable WSI status label.
        r_dev: Rainfall deviation percentage.
        g_drop: Groundwater drop in meters.
        tankers: Number of tankers allocated.
        target_language: Language for the response (default: "English").

    Returns:
        Cleaned advisory text with exactly 3 bullet points,
        or an error message string if the LLM call fails.
    """
    prompt = f"""
    You are an expert Hydrologist AI assisting the District Collector.
    Analyze the following deterministic village data and provide a strict 3-bullet point action plan.
    DO NOT perform any calculations. Use the provided data.

    Data Context:
    - Village: {village_name}
    - Population: {population}
    - Water Stress Index (WSI): {wsi}/100 (Status: {status})
    - Rainfall Deviation: {r_dev}%
    - Groundwater Drop: {g_drop}m
    - Tankers Allocated: {tankers}

    Output Format MUST be exactly 3 bullet points:
    1. Primary Cause: [One sentence explaining why the WSI is high based on the data]
    2. Impact: [One sentence on population risk]
    3. Directive: [One sentence on immediate administrative action]

    Output Language: {target_language}
    """

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
    }

    headers = {"Content-Type": "application/json"}
    if OLLAMA_API_KEY:
        headers["Authorization"] = f"Bearer {OLLAMA_API_KEY}"

    logger.info(f"Requesting AI insight for village: {village_name} (lang={target_language}, model={MODEL_NAME})")

    try:
        response = requests.post(OLLAMA_URL, json=payload, headers=headers, timeout=45)
        response.raise_for_status()

        response_data = response.json()
        raw_output = response_data.get("response", "")

        # Sanitize the output before returning
        clean_output = sanitize_ai_response(raw_output)

        logger.info(f"AI insight generated for {village_name}: {len(clean_output)} chars")
        return clean_output

    except requests.exceptions.RequestException as e:
        logger.error(f"Ollama Connection Error: {e}")
        return "Error: Unable to generate AI insight. Ensure Ollama is running locally with the correct model."
